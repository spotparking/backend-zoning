{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Stalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import yaml\n",
    "\n",
    "def load_stalls(cam_label, dtype_float=False, version=\"detection\", weight=(1, 1)):\n",
    "    \"\"\" loads the stall locations (in pixels) for a given camera label by loading the\n",
    "    stall settings in settings/<cam_label>.yaml and converting the float stall locations\n",
    "    to pixels\n",
    "    \n",
    "    the version kwarg can be 'detection', 'center', or 'average' to specify which type of stall location\n",
    "    is returned.\n",
    "    * 'detection' returns the detection point, which is the point at the centerish of the yolo car detections\n",
    "    * 'center' returns the center of the stall, which is calculated as the intersection of the vertices of the stall lines\n",
    "    * 'average' returns the average of the detection and center points\n",
    "    ! the algorithm that matches detections to stalls basically computes the distance between each point and a point in the\n",
    "        yolo bbox. The point in the yolo bbox is the point in between the center of the bbox and the middle of the bottom edge\n",
    "        of the bbox. Because of this, the detection reference point is closest to the average between the stall center and\n",
    "        the center of the yolo bbox. Sometimes the stall location isn't actually inside the yolo detection if the camera is at\n",
    "        a lower angle, so the 'center' version parameter can sometimes be inaccurate.\n",
    "    ! this average is a weighted average (3*detection_loc + 1*stall_center_loc) / 4\n",
    "    \n",
    "    Example:\n",
    "    load_stalls('000004-4-cb_northeast_north')\n",
    "    {\n",
    "        \"004-0003\": (1856, 796),\n",
    "        \"004-0004\": (1839, 703),\n",
    "        ...\n",
    "    }\n",
    "    load_stalls('000004-4-cb_northeast_north', dtype_float=True)\n",
    "    {\n",
    "        \"004-0003\": (0.96707, 0.73705),\n",
    "        \"004-0004\": (0.95783, 0.65163),\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    if version.lower() not in ('detection', 'center', 'average'):\n",
    "        raise ValueError(f\"Invalid version {version}. Must be 'detection', 'center', or 'average'\")\n",
    "    \n",
    "    settings_path = f\"../zoning_data/{cam_label}.yaml\"\n",
    "    with open(settings_path, 'r') as f:\n",
    "        settings = yaml.safe_load(f)\n",
    "    height = settings['resolution']['height']\n",
    "    width = settings['resolution']['width']\n",
    "    stalls = settings['stalls']\n",
    "    output_stalls_dict = {}\n",
    "    for spotID, stall_entry in stalls.items():\n",
    "        x, y = stall_entry['point']\n",
    "        stall_x, stall_y = stall_entry['stall_center']\n",
    "        if not dtype_float:\n",
    "            x_pix = int(x * width)\n",
    "            y_pix = int(y * height)\n",
    "            stall_x_pix = int(stall_x * width)\n",
    "            stall_y_pix = int(stall_y * height)\n",
    "            if version == 'detection':\n",
    "                res = (x_pix, y_pix)\n",
    "            elif version == 'center':\n",
    "                res = (stall_x_pix, stall_y_pix)\n",
    "            elif version == 'average':\n",
    "                res = (\n",
    "                    int((x_pix*weight[0] + stall_x_pix*weight[1]) // sum(weight)), \n",
    "                    int((y_pix*weight[0] + stall_y_pix*weight[1]) // sum(weight)))\n",
    "        else:\n",
    "            if version == 'detection':\n",
    "                res = (round(float(x), 5), round(float(y), 5))\n",
    "            elif version == 'center':\n",
    "                res = (round(float(stall_x), 5), round(float(stall_y), 5))\n",
    "            elif version == 'average':\n",
    "                res = (\n",
    "                    round((float(x)*weight[0] + float(stall_x)*weight[1]) / sum(weight), 5), \n",
    "                    round((float(y)*weight[0] + float(stall_y)*weight[1]) / sum(weight), 5))\n",
    "        output_stalls_dict[spotID] = res\n",
    "    return output_stalls_dict\n",
    "\n",
    "def get_stalls():\n",
    "    # load the settings yaml file\n",
    "    cam_label = \"000004-4-cb_northeast_north\"\n",
    "    stalls = load_stalls(cam_label, dtype_float=True, version='average')\n",
    "    # settings_path = f\"settings/{cam_label}.yaml\"\n",
    "    # with open(settings_path, \"r\") as f:\n",
    "    #     settings = yaml.safe_load(f)\n",
    "    # # create a dictionary of the stall locations\n",
    "    # stalls = {spotID: e['point'] for spotID, e in settings['stalls'].items()}\n",
    "    for spotID, point in stalls.items():\n",
    "        # shift the stalls since we crop the camera stream down to just the right half\n",
    "        x, y = point[0], point[1]\n",
    "        x_shifted, y_shifted = (x - 0.5) / 0.5, y\n",
    "        x_pix, y_pix = int(x_shifted * 1920//2), int(y_shifted * 1080)\n",
    "        stalls[spotID] = (x_pix, y_pix)\n",
    "    return stalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SPOT_YELLOW_RGB = (255, 227, 116) # spot YELLOW in RGB\n",
    "SPOT_YELLOW_HEX = \"#ffd92e\"\n",
    "SPOT_YELLOW_BGR = (116, 227, 255) # spot YELLOW in BGR\n",
    "\n",
    "def show_video(video_path, track_record, show_stalls=True, show_tracks=False, only_this_track_id=None, \n",
    "               title_string=None, skip_frames=None, plt_show=True, frame_delay=None, pause=True, track_id_col='track_id'):\n",
    "    clear_output(wait=True)  if plt_show else None # Clear the previous frame\n",
    "    # is showing the stalls enabled\n",
    "    if show_stalls:\n",
    "        # load the stalls from the YAML file\n",
    "        stalls = get_stalls()\n",
    "        # function that adds the stall location as a dot on the frame\n",
    "        # and also adds the stall number as text\n",
    "        def add_stalls_to_frame(frame, stalls):\n",
    "            for spotID, (x, y) in stalls.items():\n",
    "                cv2.circle(frame, (int(x), int(y)), 5, (30, 130, 250), -1)\n",
    "                cv2.putText(\n",
    "                    frame, \n",
    "                    str(int(spotID.replace(\"004-\", \"\"))), \n",
    "                    (int(x), int(y)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, \n",
    "                    (50, 200, 50), \n",
    "                    2\n",
    "                )\n",
    "            return frame\n",
    "        \n",
    "    # if showing the tracks is enabled\n",
    "    if show_tracks:\n",
    "        # load the track record\n",
    "        main_video_part = video_path.split(\"/\")[-1]\n",
    "        if track_record is None:\n",
    "            print(f\"Track record does not exist for this video {video_path}\")\n",
    "            return False\n",
    "        # if only wanting to observe the main track of the video, filter the track_record to just row entries with that track_id\n",
    "        if only_this_track_id is not None:\n",
    "            if isinstance(only_this_track_id, str) or isinstance(only_this_track_id, float) or isinstance(only_this_track_id, int):\n",
    "                only_this_track_id = int(only_this_track_id)\n",
    "                track_record = track_record.loc[track_record[track_id_col].astype(int) == only_this_track_id, :].copy()\n",
    "            elif isinstance(only_this_track_id, list) or isinstance(only_this_track_id, tuple) or isinstance(only_this_track_id, set):\n",
    "                only_this_track_id = set(map(int, only_this_track_id))\n",
    "                track_record = track_record.loc[track_record[track_id_col].astype(int).isin(only_this_track_id), :].copy()\n",
    "        # create a dictionary where keys are iteration numbers and the values are a numpy array\n",
    "        # with shape(n_tracks, 5) where each entry is a track_id, tl_x, tl_y, br_x, br_y\n",
    "        frame_tracks = {}\n",
    "        track_record['br_x'] = track_record['tl_x'] + track_record['w']\n",
    "        track_record['br_y'] = track_record['tl_y'] + track_record['h']\n",
    "        for iteration, frame in track_record.groupby('iteration'):\n",
    "            frame = frame.loc[frame['confirmed'], :]\n",
    "            bbox_df = frame[[track_id_col, 'confidence', 'tl_x', 'tl_y', 'br_x', 'br_y']]\n",
    "            bbox_arr = bbox_df.to_numpy().astype(float)\n",
    "            frame_tracks[int(iteration)-1] = bbox_arr\n",
    "        # function that adds the track bounding boxes to the frame with a track_id label above the top left corner\n",
    "        def add_tracks_to_frame(frame, tracks):\n",
    "            for track_id, confidence, tl_x, tl_y, br_x, br_y in frame_tracks[frame_number]:\n",
    "                track_id, tl_x, tl_y, br_x, br_y = map(int, (track_id, tl_x, tl_y, br_x, br_y))\n",
    "                cv2.rectangle(frame, (tl_x, tl_y), (br_x, br_y), SPOT_YELLOW_BGR, 2)\n",
    "                text = f\"{track_id} ({confidence:.2f})\"\n",
    "                cv2.putText(\n",
    "                    frame, \n",
    "                    text, \n",
    "                    (tl_x, tl_y), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, \n",
    "                    (200, 50, 50), \n",
    "                    2\n",
    "                )\n",
    "    \n",
    "    # loop through every frame of the video\n",
    "    frame_number = 0\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if skip_frames is not None and frame_number % skip_frames != 0:\n",
    "            frame_number += 1\n",
    "            continue\n",
    "        if not ret:\n",
    "            input(\"Press Enter to end...\") if pause else None\n",
    "            break\n",
    "        if show_stalls:\n",
    "            frame = add_stalls_to_frame(frame, stalls)\n",
    "        if show_tracks:\n",
    "            if frame_number in frame_tracks.keys():\n",
    "               add_tracks_to_frame(frame, frame_tracks[frame_number])\n",
    "        # Convert frame from BGR to RGB\n",
    "        \n",
    "        if plt_show:\n",
    "            plt.title(title_string) if title_string is not None else None\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(frame)\n",
    "            plt.axis('off')\n",
    "            plt.gcf().set_size_inches(15, 8)\n",
    "            plt.show()\n",
    "            if frame_delay is not None:\n",
    "                sleep(frame_delay)\n",
    "            clear_output(wait=True)  # Clear the previous frame\n",
    "        else:\n",
    "            cv2.imshow(title_string, frame)    \n",
    "            if frame_delay is not None:\n",
    "                sleep(frame_delay)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or cv2.getWindowProperty(title_string, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "            \n",
    "            if frame_number <= 1:\n",
    "                input(\"Press Enter to continue...\") if pause else None\n",
    "        \n",
    "        frame_number += 1\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "version_name = \"base\"\n",
    "video_name = \"rec-2024-12-20-17-36-45_small.mp4\"\n",
    "\n",
    "record = pd.read_csv(\"../zoning_data/rec-2024-12-20/CSVs/rec-2024-12-20-17-36-45_small.csv\")\n",
    "\n",
    "date_str = video_name.replace(\"rec-\", \"\").replace(\"_small.mp4\", \"\")\n",
    "date = datetime.strptime(date_str, \"%Y-%m-%d-%H-%M-%S\").replace(tzinfo=timezone.utc)\n",
    "video_path = \"../zoning_data/rec-2024-12-20/MP4s/rec-2024-12-20-17-36-45_small.mp4\"\n",
    "show_video(video_path, record, show_stalls=True, show_tracks=True, only_this_track_id=40, frame_delay=0.2, skip_frames=None, plt_show=False, pause=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spot_parking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
